{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient\n",
    "from autogen.agentchat.contrib.qdrant_retrieve_user_proxy_agent import QdrantRetrieveUserProxyAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zephyr-7b-beta running on local\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"api_base\": \"http://localhost:8001/v1\",\n",
    "        \"api_key\": \"xyz\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# define LLM configuration\n",
    "llm_config={\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "    \"request_timeout\": 800,\n",
    "    \"max_retry_period\": 50,\n",
    "    \"retry_wait_time\": 1,\n",
    "    \"cache_seed\": 42,\n",
    "    \"retry_wait_time\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure qdrant client\n",
    "client = QdrantClient(url= 'https://3b137cea-90f8-4fea-8b72-954bf21eeed1.us-east4-0.gcp.cloud.qdrant.io:6333' , api_key= \"YBM_CzRCXu_98KMmsagBUyvTK9QxkNoGJQG79D-mWywSOfEw9YlrcA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \"\\r\", \"\\t\"])\n",
    "termination_msg = lambda x: isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n",
    "\n",
    "# Assistant Agent\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config= llm_config\n",
    ")\n",
    "\n",
    "\n",
    "# Employee RAG Agent\n",
    "ragproxyagent = QdrantRetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    llm_config= llm_config,\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"task\": \"qa\",\n",
    "        \"docs_path\": \"/Users/anik/Desktop/code_repo/Sally_Harley_payslip.pdf\",\n",
    "        \"custom_text_split_function\": text_splitter.split_text,\n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"client\": client,\n",
    "        \"embedding_model\": \"BAAI/bge-base-en-v1.5\",\n",
    "        \"collection_name\": \"test1\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n",
      "\u001b[32mAdding doc_id 0 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "You must give as short an answer as possible.\n",
      "\n",
      "User's question is: what is Sally Harley's date of joining?\n",
      "\n",
      "Context is: Payslip  \n",
      "Zoonodle  Inc \n",
      "21023 Pearson Point  Road  \n",
      "Gate Avenue  \n",
      " \n",
      " \n",
      "Date of Joining  : 2018 -06-23 \n",
      "Pay Period  : August  2021  \n",
      "Worked  Days  26 Employee  Name  : Sally  Harley  \n",
      "Designation  : Marketing  Evecutive  \n",
      "Department  : Marketing  \n",
      " \n",
      " \n",
      " \n",
      "Earnings  \n",
      "Basic Pay  Amoun t  \n",
      "10000  Deductions  \n",
      "Provident  Fund  Amount   \n",
      "1200  \n",
      "Icentive Pay   1000  Profesional Tax   500 \n",
      "House Rent Allowance   400 Loan   400 \n",
      "Meal Allowance   200    \n",
      " \n",
      "Total \n",
      "Earnings   \n",
      "11600   \n",
      "Total Deductions   \n",
      "2100  \n",
      "  Net Pay  9500  \n",
      " \n",
      " \n",
      " \n",
      "9500  \n",
      "Nine Thousand Five Hundred  \n",
      " \n",
      " \n",
      "Employer  Signature  Employee  Signature  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "This is system generated payslip\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "User's question is: what is Sally Harley's date of joining?\n",
      "\n",
      "Context provided: Payslip for Sally Harley with her date of joining listed as \"2018 -06-23\".\n",
      "\n",
      "Answer: Sally Harley joined on June 23, 2018.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "assistant.reset()\n",
    "\n",
    "qa_problem = \"what is Sally Harley's date of joining?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('gbi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e19069da8a903c0488258ed75f4ad20d4156f00f2c3d125829276d3149665737"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
